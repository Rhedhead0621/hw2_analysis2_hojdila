{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# HW 2 - Analysis 2 - Batch by File Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I'm sure it can be cleaner, and made into some kind of function doc like the whatif.py?*** \n",
    "\n",
    "***It's not exactly what you asked for, but it will batch every three letter combination the user initiates***\n",
    "\n",
    "## Please use FCM for the example\n",
    "\n",
    "***I deleted the directories and files, so you can see what it does - otherwise there are errors because the folders already exist, duplicate headers, etc.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# To auto-reload modules in jupyter notebook (so that changes in files *.py doesn't require manual reloading):\n",
    "# https://stackoverflow.com/questions/5364050/reloading-submodules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Import commonly used libraries and magic command for inline plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import openpyxl\n",
    "from openpyxl.styles import Alignment\n",
    "import csv\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 1 â€“ Consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ask for which file types to batch - use FCM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Enter the three letter file ID to batch:')\n",
    "f_id = input()\n",
    "print('We will begin batch processing log files that begin with: ' + f_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Make the new directory and copy the original files first, so only modifying copies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy all original files\n",
    "\n",
    "# Specify the source directory path\n",
    "source_directory = './data/logs/'\n",
    "\n",
    "copies_directory = './data/log_copies/'\n",
    "\n",
    "destination_directory = os.path.join(copies_directory, f_id)\n",
    "\n",
    "os.mkdir(destination_directory)\n",
    "\n",
    "# Get a list of all files in the source directory\n",
    "files = glob.glob(source_directory + '/' + f_id + '*.csv')\n",
    "\n",
    "# Copy each file to the destination directory\n",
    "for file in files:\n",
    "   shutil.copy(file, destination_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I wanted to confirm the destination_directory could be used in the remainder of the processes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "destination_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Added a header to each csv file in the copies folder***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add header to each file copy\n",
    "\n",
    "filelist = glob.glob(destination_directory + \"/*.csv\")\n",
    "df_list = []\n",
    "for file in filelist:\n",
    "# you also dont need to add path, the glob should already have the full path\n",
    "    df2 = read_csv(file,names=['datetime','scale','temperature'])\n",
    "    ## save out files\n",
    "    df2.to_csv(file,index=False)\n",
    "    df_list.append(df2)\n",
    "frame = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Places each csv file onto one sheet in the workbook, this also creates the file - I'm going to use different files names as I step through this process***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy each csv file to a workbook sheet\n",
    "\n",
    "path = destination_directory\n",
    "\n",
    "def write_sheets(file_map: dict) -> None:\n",
    "    with pd.ExcelWriter(f\"{path}/{f_id}_v1.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "        [df.to_excel(writer, sheet_name=sheet_name, index=False) for sheet_name, df in file_map.items()]\n",
    "\n",
    "file_mapping = {Path(file).stem: pd.read_csv(file) for file in Path(path).glob(\"*.csv\")}\n",
    "write_sheets(file_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sorting each sheet by column A, to get the min and max datetime values later***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort each sheet by column A, in version 1\n",
    "\n",
    "# Load the Excel workbook\n",
    "workbook = openpyxl.load_workbook(f\"{destination_directory}/{f_id}_v1.xlsx\")\n",
    "\n",
    "# Iterate through each sheet\n",
    "for sheet_name in workbook.sheetnames:\n",
    "    sheet = workbook[sheet_name]\n",
    "    \n",
    "    # Extract data from column A\n",
    "    column_a_data = []\n",
    "    for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, min_col=1, max_col=1):\n",
    "        column_a_data.append(row[0].value)\n",
    "    \n",
    "    # Sort rows based on values in column A\n",
    "    sorted_rows = sorted(sheet.iter_rows(min_row=2, max_row=sheet.max_row, min_col=1),\n",
    "                          key=lambda x: x[0].value)\n",
    "    \n",
    "    # Rewrite sorted data back to the sheet\n",
    "    for idx, row in enumerate(sorted_rows, start=2):\n",
    "        for col_idx, cell in enumerate(row, start=1):\n",
    "            sheet.cell(row=idx, column=col_idx).value = cell.value\n",
    "\n",
    "# Save the changes to the workbook\n",
    "workbook.save(f\"{destination_directory}/{f_id}_sorted.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Adding the formulas to the sorted file, adjusting the columns to autofit the width, and fixing the alignment of the min/max datetimes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add the formulas to each workbook sheet - using the sorted file\n",
    "\n",
    "# Load the Excel workbook\n",
    "workbook = openpyxl.load_workbook(f\"{destination_directory}/{f_id}_sorted.xlsx\")\n",
    "\n",
    "# Iterate through each sheet in the workbook\n",
    "for sheet_name in workbook.sheetnames:\n",
    "    sheet = workbook[sheet_name]\n",
    "    \n",
    "    # Add labels to cells G2:G7\n",
    "    sheet['G2'] = 'min_temp'\n",
    "    sheet['G3'] = 'max_temp'\n",
    "    sheet['G4'] = 'mean_temp'\n",
    "    sheet['G6'] = 'min_date'\n",
    "    sheet['G7'] = 'max_date'\n",
    "    \n",
    "    # Add formulas to cell H2:H7\n",
    "    sheet['H2'] = '=ROUND(MIN(C:C),1)'\n",
    "    sheet['H3'] = '=ROUND(MAX(C:C),1)'\n",
    "    sheet['H4'] = '=ROUND(AVERAGE(C:C),1)'\n",
    "    sheet['H6'] = '=A2'\n",
    "    col_a_length = len(sheet['A'])\n",
    "    sheet['H7'] = '=A' + str(col_a_length)\n",
    "    \n",
    "    # Align cells H6 and H7 to the right\n",
    "    sheet['H6'].alignment = Alignment(horizontal='right')\n",
    "    sheet['H7'].alignment = Alignment(horizontal='right')\n",
    "    \n",
    "    # Iterate through each column in the worksheet\n",
    "    for col in sheet.columns:\n",
    "        max_length = 0\n",
    "        \n",
    "        # Iterate through each cell in the column to find the maximum length\n",
    "        for cell in col:\n",
    "            try:\n",
    "                # Check if the cell contains a string and update the maximum length\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Autofit the column width based on the maximum length\n",
    "        sheet.column_dimensions[col[0].column_letter].width = max_length + 2  # Add some extra space\n",
    "\n",
    "# Save the changes to the workbook\n",
    "workbook.save(f\"{destination_directory}/{f_id}_Final.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The final .xlsx should be all set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aap]",
   "language": "python",
   "name": "conda-env-aap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
